{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka producer that will read “SalesRecords.csv” file and convert each line to json and send the data to a Kafka topic(“test.topic.raw”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Region': 'Sub-Saharan Africa', 'Country': 'South Africa', 'Item Type': 'Fruits', 'Sales Channel': 'Offline', 'Order Priority': 'M', 'Order Date': '7/27/2012', 'Order ID': '443368995', 'Ship Date': '7/28/2012', 'Units Sold': '1593', 'Unit Price': '9.33', 'Unit Cost': '6.92', 'Total Revenue': '14862.69', 'Total Cost': '11023.56', 'Total Profit': '3839.13'}\n",
      "{'Region': 'Middle East and North Africa', 'Country': 'Morocco', 'Item Type': 'Clothes', 'Sales Channel': 'Online', 'Order Priority': 'M', 'Order Date': '9/14/2013', 'Order ID': '667593514', 'Ship Date': '10/19/2013', 'Units Sold': '4611', 'Unit Price': '109.28', 'Unit Cost': '35.84', 'Total Revenue': '503890.08', 'Total Cost': '165258.24', 'Total Profit': '338631.84'}\n",
      "{'Region': 'Australia and Oceania', 'Country': 'Papua New Guinea', 'Item Type': 'Meat', 'Sales Channel': 'Offline', 'Order Priority': 'M', 'Order Date': '5/15/2015', 'Order ID': '940995585', 'Ship Date': '6/4/2015', 'Units Sold': '360', 'Unit Price': '421.89', 'Unit Cost': '364.69', 'Total Revenue': '151880.40', 'Total Cost': '131288.40', 'Total Profit': '20592.00'}\n",
      "{'Region': 'Sub-Saharan Africa', 'Country': 'Djibouti', 'Item Type': 'Clothes', 'Sales Channel': 'Offline', 'Order Priority': 'H', 'Order Date': '5/17/2017', 'Order ID': '880811536', 'Ship Date': '7/2/2017', 'Units Sold': '562', 'Unit Price': '109.28', 'Unit Cost': '35.84', 'Total Revenue': '61415.36', 'Total Cost': '20142.08', 'Total Profit': '41273.28'}\n",
      "Stopped.\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaAdminClient, KafkaConsumer, KafkaProducer\n",
    "from kafka.admin import NewTopic\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from json import loads\n",
    "from csv import DictReader\n",
    "\n",
    "# Required setting for Kafka Producer\n",
    "bootstrap_servers = ['localhost:9092']\n",
    "topicname = 'test.topic'\n",
    "producer = KafkaProducer(bootstrap_servers = bootstrap_servers)\n",
    "producer = KafkaProducer()\n",
    "\n",
    "\n",
    "# iterate over each line as a ordered dictionary and print only few column by column name\n",
    "with open('SalesRecords.csv','r') as read_obj:\n",
    "    csv_dict_reader = DictReader(read_obj)\n",
    "    try:\n",
    "        for row in csv_dict_reader:\n",
    "            ack = producer.send(topicname, json.dumps(row).encode('utf-8'))\n",
    "            time_to_sleep = random.randint(1, 11)\n",
    "            time.sleep(time_to_sleep)\n",
    "            metadata = ack.get()\n",
    "            #print(metadata.topic)\n",
    "            print(row)\n",
    "            print()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
